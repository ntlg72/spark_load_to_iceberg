FROM bitnami/spark:latest

USER root

# Instala Java 17 y utilidades necesarias
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    openjdk-17-jdk-headless \
    procps \
    curl \
    wget \
    && rm -rf /var/lib/apt/lists/*

# Configura JAVA_HOME
ENV JAVA_HOME=/usr/lib/jvm/java-17-openjdk-amd64
ENV PATH=$JAVA_HOME/bin:$PATH

# Crear usuario spark si no existe y definir HOME
RUN useradd -m spark || true
ENV HOME=/home/spark

# Crear directorios necesarios y asignar permisos
RUN mkdir -p /opt/bitnami/spark/jars /opt/bitnami/spark/tmp && \
    chown -R spark:spark /opt/bitnami/spark/jars /opt/bitnami/spark/tmp

USER spark

# Copiar requirements.txt si necesitas instalar paquetes Python
COPY requirements.txt /tmp/requirements.txt
RUN pip install --no-cache-dir -r /tmp/requirements.txt || true

USER root

# Descargar JARs de Hadoop, AWS SDK, Guava, Iceberg y Nessie
RUN wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-aws/3.2.0/hadoop-aws-3.2.0.jar -P /opt/bitnami/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/com/amazonaws/aws-java-sdk/1.11.1000/aws-java-sdk-1.11.1000.jar -P /opt/bitnami/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/com/google/guava/guava/30.1.1-jre/guava-30.1.1-jre.jar -P /opt/bitnami/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/3.2.0/hadoop-common-3.2.0.jar -P /opt/bitnami/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/apache/iceberg/iceberg-spark-runtime-3.5_2.12/1.5.0/iceberg-spark-runtime-3.5_2.12-1.5.0.jar -P /opt/bitnami/spark/jars/ && \
    wget -q https://repo1.maven.org/maven2/org/projectnessie/nessie-spark-extensions-3.5_2.12/0.77.1/nessie-spark-extensions-3.5_2.12-0.77.1.jar -P /opt/bitnami/spark/jars/

# Permisos finales
RUN chown -R spark:spark /opt/bitnami/spark/jars /opt/bitnami/spark/tmp

USER spark
